I started by writing the 1s and 0s parser as instructed, but after doing that I
decided I wanted my program to be able to reliably tokenize a given file before
doing any of the actual syntax.

The reason I chose to do it this way is that I knew my testing strategy for the
Syntax was most likely going to involve writing some .nal files and running them.

Which wouldn't have been possible without sorting out all of the file reading
infrastructure.
All of that code was easy to test function by function.

Then I started building the parser one command at a time, for each new command
I wrote a new .nal file which only tested that particular piece of syntax.
I also wrote a .nal file which was supposed to break at that particular syntax, and checked that when it terminated the program no leaks happened.

For example by having a .nal file which only contained a {, I noticed that the program was not terminating correctly.
And that was because, after completing an instruction I was simply increasing the current word index by 1.
But what happens if the current word is the last one?? Then when trying to read the next word, the program would be reading outside of the array!
To fix this I wrote the wordStep(int s) function, which increases the current word index by s, but also checks that the new index is withing the array, and returns an error if it is not.

Next I wrote the interpeter code for <FILE> and <ABORT>. I chose to work on these functions first because they do not deal with Variables or Conditionals, and also it looked like building these functions required a large change in the file structures in order to allow .nal files to properly interact with each other.

After working on it for a while though I realized that wasn't true.
<FILE> only required calling program() with the new .nal file within the file() function.
It was quite easy to test this function using .nal files as I could just write .nal files calling one another and check if they parsed correctly (by not having the "Parsed OK" print inside a #ifndef -INTERP).
<ABORT> was a little more complicated, I had already built and tested a terminateNalFile() function, but I had to expand this to be able to terminate all open files if more than one was opened with the file() function.
To do so I simply added a pointer in the nalFile structure which points to the "previous file", this way if ABORT is called, it is simple to go down this linked list and close each file.
Again, this function was easy to test using .nal files which opened each other using <FILE> and check that if ABORT was called no memory leaks happened.

In order to read the string constant after a FILE command I had to write a function to deal with string constants, which involved playing with the ROT18 algorithm.

When testing the ROT function, I first encountered some issues using the % operator, it wasn't dealing properly with negative values so I used an if statement instead. Then when writing the arrays I used for testing lots of weird stuff kept happening until i realized I needed to add 1 to the size of each array for the end of string char.

Then I moved onto <JUMP>, since it also doesn't deal with variables. It was quite simple to write given that the words are stored as an array, and to test I tried it on the .nal files which is an infinite loop.

Now it was time to start playing with variables though, so I took inspiration from our work with mvms and wrote another set of files called vList .c, .h and testvList.c for testing.
These files will have all the functions required to handle variables.
I stored all variables as strings.

Testing these functions was easy because we already had a testfile setup for mvm, so I slightly adapted that, surprisingly I didn't encounter any errors while testing this (except a bunch of syntax errors like missing commas and things like that).
